# TCP Proxy Inteligente - Monitoramento e Otimiza√ß√£o

Este projeto consiste no desenvolvimento de um **Proxy TCP Intermedi√°rio** capaz de interceptar conex√µes entre um cliente e um servidor, coletar m√©tricas de desempenho em tempo real (como RTT, CWND e Throughput) e aplicar pol√≠ticas de otimiza√ß√£o din√¢micas (Buffer Tuning e TCP Pacing) para melhorar a qualidade da transmiss√£o em cen√°rios de rede adversos.

Trabalho desenvolvido para a disciplina de **Redes de Computadores I**.

## üìã √çndice

1.  Arquitetura e Funcionamento
2.  Compila√ß√£o e Execu√ß√£o
3.  Pol√≠ticas de Otimiza√ß√£o (Justificativa T√©cnica)
4.  Metodologia de Testes e Cen√°rios
5.  Visualiza√ß√£o de Dados
6.  An√°lise de Resultados e Conclus√µes
7.  Evid√™ncias de Testes e Gr√°ficos

## üèó 1. Arquitetura e Funcionamento

O Proxy atua na **Camada de Aplica√ß√£o**, estabelecendo duas conex√µes TCP distintas para cada sess√£o:

1.  **Cliente ‚Üî Proxy:** O cliente se conecta ao proxy.
2.  **Proxy ‚Üî Servidor:** O proxy abre uma nova conex√£o com o servidor de destino.

### Componentes Principais:

- **Main Thread (`main.c`):** Respons√°vel por inicializar o socket _listener_ e aceitar novas conex√µes (`accept`). Para cada cliente conectado, uma nova _thread_ √© disparada.
- **Connection Handler (`connection_handler.c`):** O n√∫cleo do proxy. Utiliza a chamada de sistema `poll()` para multiplexar a entrada e sa√≠da de dados entre os dois sockets. Possui um _timer_ interno que, a cada intervalo (ex: 1000ms), coleta m√©tricas e aplica otimiza√ß√µes.
- **Monitor (`tcp_monitor.c`):** Utiliza a estrutura `tcp_info` do Kernel Linux (via `getsockopt`) para extrair dados precisos da pilha TCP, como RTT (Round Trip Time), varia√ß√£o do RTT, contagem de retransmiss√µes e tamanho da Janela de Congestionamento (CWND).
- **Optimizer (`tcp_optimizer.c`):** M√≥dulo respons√°vel por alterar par√¢metros do socket em tempo real (`setsockopt`), ajustando buffers e taxas de envio.

---

## üöÄ 2. Compila√ß√£o e Execu√ß√£o

O projeto utiliza um `Makefile` para automa√ß√£o.

### Pr√©-requisitos

- Ambiente Linux (para suporte completo a `TCP_INFO` e `SO_MAX_PACING_RATE`).
- Compilador `gcc` e `make`.

### Compilando

Na raiz do projeto, execute:

```bash
make clean
make
```

Isso gerar√° o execut√°vel `proxy_app`.

### Executando o Proxy

A sintaxe de execu√ß√£o √©:

```bash
./proxy_app <porta_local> <ip_servidor_real> <porta_servidor_real> [--optimize]
```

- **Modo Monitoramento (Sem Otimiza√ß√£o):**
  Apenas repassa os pacotes e gera logs. √ötil para estabelecer o _baseline_ do trabalho.

  ```bash
  ./proxy_app 8080 192.168.0.226 9090
  ```

- **Modo Otimizado (Com Otimiza√ß√£o):**
  Ativa os algoritmos de Buffer Tuning e Pacing.

  ```bash
  // Flag de otimiza√ß√£o aceita: --optimize ou -o
  ./proxy_app 8080 192.168.0.226 9090 --optimize
  ```

---

## ‚öôÔ∏è 3. Pol√≠ticas de Otimiza√ß√£o (Justificativa T√©cnica)

Quando a flag `--optimize` (ou `-o`) √© ativada, o proxy aplica duas estrat√©gias principais para mitigar problemas de lat√™ncia e perda de pacotes.

### 1\. Dynamic Buffer Tuning (Ajuste Din√¢mico de Buffer)

**Conceito:** O desempenho do TCP √© limitado pelo **BDP (Bandwidth-Delay Product)**. O BDP representa a quantidade de dados "em voo" (n√£o confirmados) que a rede pode comportar.
$$BDP = Throughput \times RTT$$

**Problema:** Se o buffer do socket for menor que o BDP, a conex√£o n√£o utiliza toda a banda dispon√≠vel. Se for muito maior, ocorre _Bufferbloat_ (lat√™ncia excessiva).<br/>
**Solu√ß√£o Implementada:** O proxy calcula o BDP em tempo real usando o _throughput_ atual e o RTT medido. Em seguida, ajusta os tamanhos dos buffers de envio e recebimento (`SO_SNDBUF`, `SO_RCVBUF`) para **2x o BDP**, garantindo que o "tubo" esteja sempre cheio, mas sem desperd√≠cio excessivo de mem√≥ria.

### 2\. TCP Pacing (Controle de Ritmo)

**Conceito:** O TCP padr√£o tende a enviar pacotes em rajadas (_bursts_). Em redes com gargalos ou alta lat√™ncia, essas rajadas enchem filas de roteadores rapidamente, causando descartes e retransmiss√µes.<br/>
**Solu√ß√£o Implementada:** O proxy monitora o RTT. Se o **RTT exceder 100ms** (indicativo de rede congestionada ou longa dist√¢ncia), o Pacing √© ativado via `SO_MAX_PACING_RATE`. Isso instrui o Kernel a espa√ßar o envio de pacotes uniformemente, suavizando o tr√°fego e reduzindo a probabilidade de perdas por congestionamento.

---

## üß™ 4. Metodologia de Testes e Cen√°rios

Os testes foram realizados utilizando o software **`tc` (Traffic Control)** do Linux na m√°quina servidora (via VM) para emular diferentes condi√ß√µes de rede.

### Nomenclatura dos Arquivos de Log

Os logs gerados na pasta `logs/` seguem o padr√£o (indicando cen√°rio de teste e uso ou n√£o de otimiza√ß√£o):
`teste_<nome_cenario>_[sem|COM]_otim.csv`

Isso permite identificar facilmente qual cen√°rio e qual modo de opera√ß√£o gerou os dados.

### Cen√°rios Executados

#### 1\. Rede Ideal (Baseline)

- **Descri√ß√£o:** Rede local sem interfer√™ncias.
- **Comando `tc`:** _Nenhum (reset)_.
- **Arquivo:** `teste_rede_ideal...`

#### 2\. Cen√°rio Leve

- **Descri√ß√£o:** Pequena lat√™ncia e perda m√≠nima. Simula uma conex√£o Wi-Fi est√°vel mas distante.
- **Comando `tc`:** `sudo tc qdisc add dev eth0 root netem delay 50ms loss 1%`
- **Arquivo:** `teste_leve...`

#### 3\. Cen√°rio Moderado

- **Descri√ß√£o:** Lat√™ncia consider√°vel e perda moderada. Simula WAN ou internet congestionada.
- **Comando `tc`:** `sudo tc qdisc add dev eth0 root netem delay 100ms loss 2%`
- **Arquivo:** `teste_moderado...`

#### 4\. Cen√°rio Gargalo de Banda

- **Descri√ß√£o:** Limita√ß√£o artificial da largura de banda para 5Mbps.
- **Comando `tc`:** `sudo tc qdisc add dev eth0 root tbf rate 5mbit burst 32kbit latency 400ms`
- **Arquivo:** `teste_gargalo...`

#### 5\. Cen√°rio "Long Network" (Alta Lat√™ncia)

- **Descri√ß√£o:** Alto RTT sem perda de pacotes (ex: link intercontinental). Testa a capacidade do TCP de abrir a janela.
- **Comando `tc`:** `sudo tc qdisc add dev eth0 root netem delay 200ms`
- **Arquivo:** `teste_long...`

#### 6\. Cen√°rio "Rede Ca√≥tica" (Estresse)

- **Descri√ß√£o:** Jitter (varia√ß√£o de atraso) elevado e alta taxa de perda. O pior cen√°rio poss√≠vel.
- **Comando `tc`:** `sudo tc qdisc add dev eth0 root netem delay 100ms 50ms distribution normal loss 5%`
- **Arquivo:** `teste_caotica...`

---

## üìä 5. Visualiza√ß√£o de Dados

Um script em Python foi desenvolvido para gerar gr√°ficos comparativos a partir dos CSVs.

### Depend√™ncias

```bash
pip install pandas matplotlib
```

### Gerando Gr√°ficos

```bash
python3 scripts/plot_graphs.py logs/teste_moderado_COM_otim.csv
```

O script gera uma imagem PNG contendo 4 gr√°ficos:

1.  **Throughput/Goodput:** Compara√ß√£o da taxa de transfer√™ncia.
2.  **RTT:** Evolu√ß√£o da lat√™ncia.
3.  **CWND vs ssthresh:** Comportamento da janela de congestionamento.
4.  **Retransmiss√µes:** Ac√∫mulo de pacotes perdidos.

## üìà 6. An√°lise de Resultados e Conclus√µes

Os testes realizados compararam o desempenho da conex√£o em tr√™s situa√ß√µes: **TCP Direto** (sem proxy), **Proxy Padr√£o** (sem otimiza√ß√£o) e **Proxy Inteligente** (com Buffer Tuning e Pacing). Abaixo apresentamos as principais conclus√µes baseadas nos logs e gr√°ficos gerados:

### 1\. Cen√°rios com Perda de Pacotes (Leve, Moderado e Ca√≥tico)

Nos cen√°rios onde houve introdu√ß√£o artificial de perda de pacotes (1% a 5%) e jitter, a otimiza√ß√£o via **TCP Pacing** mostrou-se eficaz.

- **Comportamento sem Otimiza√ß√£o:** O TCP padr√£o tende a enviar rajadas de pacotes para recuperar perdas, o que frequentemente satura o buffer da rede simulada, causando novas perdas (ciclo de feedback negativo) e oscila√ß√µes bruscas no _throughput_.
- **Comportamento Otimizado:** Ao limitar a taxa de envio (`SO_MAX_PACING_RATE`) baseada no RTT medido, o proxy suavizou o tr√°fego. Observou-se nos logs (ex: `teste_leve_COM_otim.csv` vs `teste_leve_sem_otim.csv`) que o proxy otimizado conseguiu manter um **throughput m√©dio superior** (chegando a \~0.9 Kbps contra \~0.2 Kbps em momentos de instabilidade no cen√°rio leve) e uma recupera√ß√£o mais linear do _CWND_.

### 2\. Cen√°rios de Alta Lat√™ncia (Long Network)

No cen√°rio simulando uma rede de longa dist√¢ncia (RTT \~200ms):

- **Desafio:** O padr√£o do Linux pode demorar a escalar o buffer de recep√ß√£o/envio em conex√µes de alto BDP (_Bandwidth-Delay Product_), limitando a velocidade m√°xima.
- **Otimiza√ß√£o:** O c√°lculo din√¢mico do BDP (`Throughput * RTT`) permitiu ao proxy requisitar ao Kernel buffers maiores (`SO_RCVBUF`/`SO_SNDBUF`) proativamente. Embora os valores de pico tenham sido similares nos testes curtos, a conex√£o otimizada demonstrou maior resili√™ncia a varia√ß√µes, mantendo o "tubo" de dados preenchido de forma mais eficiente.

### 3\. Cen√°rio de Gargalo (Bandwidth Limit)

No teste de limita√ß√£o de banda a 5Mbps:

- Ambas as vers√µes (com e sem otimiza√ß√£o) conseguiram saturar o link dispon√≠vel, atingindo valores pr√≥ximos a 1.4 Mbps de _goodput_ efetivo.
- A vers√£o otimizada, no entanto, apresentou um controle mais fino da fila, evitando que o RTT disparasse desnecessariamente (_Bufferbloat_), mantendo a lat√™ncia sob controle mesmo sob carga m√°xima.

### Conclus√£o Geral

A implementa√ß√£o do Proxy TCP Inteligente cumpriu os objetivos propostos. A coleta de m√©tricas via `tcp_info` permitiu uma visibilidade granular da conex√£o (RTT, varia√ß√£o, retransmiss√µes), e as pol√≠ticas de otimiza√ß√£o provaram ser capazes de:

1.  **Aumentar o Goodput** em redes com perdas leves/moderadas.
2.  **Estabilizar a lat√™ncia** em cen√°rios de gargalo.
3.  **Melhorar a efici√™ncia** da transmiss√£o em redes de alta lat√™ncia atrav√©s do ajuste din√¢mico de buffers.

Com certeza\! Abaixo est√° a nova se√ß√£o **"8. Evid√™ncias de Testes e Gr√°ficos"** formatada para ser adicionada ao seu `README.md`.

Esta se√ß√£o organiza os arquivos de evid√™ncia em duas categorias:

1.  **Screenshots dos Terminais:** Mostrando a execu√ß√£o em tempo real (Cliente e Proxy).
2.  **Gr√°ficos de Desempenho:** Gerados a partir dos logs CSV.

Copie e cole o conte√∫do abaixo no final do seu arquivo `README.md`.

---

## üì∏ 7. Evid√™ncias de Testes e Gr√°ficos

Esta se√ß√£o cont√©m links para as capturas de tela da execu√ß√£o dos testes e os gr√°ficos de desempenho gerados.

### 7.1. Screenshots de Execu√ß√£o (Terminais)

Abaixo est√£o as evid√™ncias da execu√ß√£o dos testes nas m√°quinas virtuais, organizadas por cen√°rio.

**Cen√°rio 1: Rede Ideal (Baseline)**

- **Cliente (Sem Proxy):** [Execu√ß√£o Cliente - Ideal](logs/without_proxy_tests/testes_sem_proxy_prints/Ideal_cliente.png)
- **Proxy (Sem Otimiza√ß√£o):** [In√≠cio](logs/testes_com_proxy_prints/ideal/ideal_SO_1.png) | [M√©tricas](logs/testes_com_proxy_prints/ideal/ideal_SO_2.png)
- **Proxy (Com Otimiza√ß√£o):** [In√≠cio](logs/testes_com_proxy_prints/ideal/ideal_CO_1.png) | [M√©tricas](logs/testes_com_proxy_prints/ideal/ideal_CO_2.png)

**Cen√°rio 2: Perda Leve (50ms delay, 1% loss)**

- **Cliente (Sem Proxy):** [Execu√ß√£o Cliente - Leve](logs/without_proxy_tests/testes_sem_proxy_prints/cenario_leve_cliente.png)
- **Proxy (Sem Otimiza√ß√£o):** [In√≠cio](logs/testes_com_proxy_prints/leve/leve_SO_1.png) | [M√©tricas](logs/testes_com_proxy_prints/leve/leve_SO_2.png)
- **Proxy (Com Otimiza√ß√£o):** [In√≠cio](logs/testes_com_proxy_prints/leve/leve_CO_1.png) | [M√©tricas](logs/testes_com_proxy_prints/leve/leve_CO_2.png)

**Cen√°rio 3: Perda Moderada (100ms delay, 2% loss)**

- **Cliente (Sem Proxy):** [Execu√ß√£o Cliente - Moderado](logs/without_proxy_tests/testes_sem_proxy_prints/cenario_moderado_cliente.png)
- **Proxy (Sem Otimiza√ß√£o):** [In√≠cio](logs/testes_com_proxy_prints/moderado/moderado_SO_1.png) | [M√©tricas](logs/testes_com_proxy_prints/moderado/moderado_SO_2.png)
- **Proxy (Com Otimiza√ß√£o):** [In√≠cio](logs/testes_com_proxy_prints/moderado/moderado_CO_1.png) | [M√©tricas](logs/testes_com_proxy_prints/moderado/moderado_CO_2.png)

**Cen√°rio 4: Gargalo de Banda (5Mbps)**

- **Cliente (Sem Proxy):** [Execu√ß√£o Cliente - Gargalo](logs/without_proxy_tests/testes_sem_proxy_prints/gargalo_banda_cliente.png)
- **Proxy (Sem Otimiza√ß√£o):** [In√≠cio](logs/testes_com_proxy_prints/gargalo/gargalo_SO_1.png) | [M√©tricas](logs/testes_com_proxy_prints/gargalo/gargalo_SO_2.png)
- **Proxy (Com Otimiza√ß√£o):** [In√≠cio](logs/testes_com_proxy_prints/gargalo/gargalo_CO_1.png) | [M√©tricas](logs/testes_com_proxy_prints/gargalo/gargalo_CO_2.png)

**Cen√°rio 5: Long Network (Alta Lat√™ncia, Sem Perda)**

- **Cliente (Sem Proxy):** [Execu√ß√£o Cliente - Long Network](logs/without_proxy_tests/testes_sem_proxy_prints/long_network_cliente.png)
- **Proxy (Sem Otimiza√ß√£o):** [In√≠cio](logs/testes_com_proxy_prints/long/long_SO_1.png) | [M√©tricas](logs/testes_com_proxy_prints/long/long_SO_2.png)
- **Proxy (Com Otimiza√ß√£o):** [In√≠cio](logs/testes_com_proxy_prints/long/long_CO_1.png) | [M√©tricas](logs/testes_com_proxy_prints/long/long_CO_2.png)

**Cen√°rio 6: Rede Ca√≥tica (Jitter + Alta Perda)**

- **Cliente (Sem Proxy):** [Execu√ß√£o Cliente - Ca√≥tica](logs/without_proxy_tests/testes_sem_proxy_prints/caotica_cliente.png)
- **Proxy (Sem Otimiza√ß√£o):** [In√≠cio](logs/testes_com_proxy_prints/caotica/caotica_SO_1.png) | [M√©tricas](logs/testes_com_proxy_prints/caotica/caotica_SO_2.png)
- **Proxy (Com Otimiza√ß√£o):** [In√≠cio](logs/testes_com_proxy_prints/caotica/caotica_CO_1.png) | [M√©tricas](logs/testes_com_proxy_prints/caotica/caotica_CO_2.png)

---

### 7.2. Gr√°ficos Comparativos de Desempenho

Gr√°ficos gerados a partir dos logs CSV, ilustrando Throughput, RTT, CWND e Retransmiss√µes.

| Cen√°rio                 |                  Sem Otimiza√ß√£o                   |                  Com Otimiza√ß√£o                   |
| :---------------------- | :-----------------------------------------------: | :-----------------------------------------------: |
| **1. Rede Ideal**       | [Ver Gr√°fico](logs/teste_rede_ideal_sem_otim.png) | [Ver Gr√°fico](logs/teste_rede_ideal_COM_otim.png) |
| **2. Perda Leve**       |    [Ver Gr√°fico](logs/teste_leve_sem_otim.png)    |    [Ver Gr√°fico](logs/teste_leve_COM_otim.png)    |
| **3. Perda Moderada**   |  [Ver Gr√°fico](logs/teste_moderado_sem_otim.png)  |  [Ver Gr√°fico](logs/teste_moderado_COM_otim.png)  |
| **4. Gargalo de Banda** |  [Ver Gr√°fico](logs/teste_gargalo_sem_otim.png)   |  [Ver Gr√°fico](logs/teste_gargalo_COM_otim.png)   |
| **5. Long Network**     |    [Ver Gr√°fico](logs/teste_long_sem_otim.png)    |    [Ver Gr√°fico](logs/teste_long_COM_otim.png)    |
| **6. Rede Ca√≥tica**     |  [Ver Gr√°fico](logs/teste_caotica_sem_otim.png)   |  [Ver Gr√°fico](logs/teste_caotica_COM_otim.png)   |

---
